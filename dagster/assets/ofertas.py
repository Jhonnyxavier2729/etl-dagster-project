from dagster import asset, AssetExecutionContext
import pandas as pd
from pymongo import MongoClient
from sqlalchemy import create_engine, exc
import duckdb
import os

@asset(group_name="ofertas")
def raw_data_ofertas(context: AssetExecutionContext):
    """Extraer datos del CSV con detecci√≥n autom√°tica inteligente"""
    context.log.info("üì• Extrayendo datos del CSV ofertas...")
    
    try:
        file_path = '/data/input/ofertas.csv'
        
        # ‚úÖ M√âTODO INTELIGENTE - pandas detecta autom√°ticamente
        df = pd.read_csv(file_path, sep=None, engine='python')
        
        context.log.info("‚úÖ CSV le√≠do con detecci√≥n autom√°tica de delimitador")
        context.log.info(f"üìä Datos extra√≠dos: {len(df)} registros, {len(df.columns)} columnas")
        context.log.info(f"üìù Columnas: {list(df.columns)}")
        
        # Informaci√≥n sobre tipos de datos
        context.log.info("üîç Tipos de datos iniciales:")
        for col, dtype in df.dtypes.items():
            context.log.info(f"   - {col}: {dtype}")
        
        return df
        
    except Exception as e:
        context.log.error(f"‚ùå Error en extracci√≥n: {str(e)}")
        raise


#asset para transformar y limpiar datos
@asset(group_name="ofertas")
def clean_data_ofertas(context: AssetExecutionContext, raw_data_ofertas: pd.DataFrame):
    """Transformar y limpiar datos - Depende de raw_data"""
    context.log.info("üîÑ Iniciando transformaci√≥n de datos...")
    
    try:
        # Hacer copia del DataFrame original
        df_clean = raw_data_ofertas.copy()
        
        context.log.info(f"üì• Datos recibidos: {df_clean.shape[0]} filas x {df_clean.shape[1]} columnas")
        
        # ‚ùå 1. Convertir todas las columnas a string
        context.log.info("üîÑ Convirtiendo todas las columnas a string...")
        df_clean = df_clean.astype(str)
        context.log.info(f"Tipos de columnas: {df_clean.dtypes.to_dict()}")


        # 2. ‚úÖ Ahora reemplazar TODOS los valores "vac√≠os"
        context.log.info("üîÑ Reemplazando valores vac√≠os por 'NA'...")
        df_clean = df_clean.replace({
            'nan': 'NA',      # NaN convertidos a string
            'None': 'NA',     # None convertidos a string  
            '': 'NA',         # Strings vac√≠os
            ' ': 'NA',        # Espacios en blanco
            '  ': 'NA',       # M√∫ltiples espacios
            '@': 'NA',         # Arrobas sueltas
            '0000000': 'NA'   # Ceros sueltos

        })
        
        
        # Log de resultados
        context.log.info("‚úÖ Transformaci√≥n completada:")
        context.log.info(f"   - Registros finales: {len(df_clean)}")
        context.log.info(f"   - Columnas: {len(df_clean.columns)}")
        context.log.info(f"   - Tipos de datos: Todos convertidos a string")
        
        # Muestra de verificaci√≥n
        context.log.info("üëÄ Vista previa de datos limpios:")
        for col in df_clean.columns[:3]:  # Primeras 3 columnas
            unique_count = df_clean[col].nunique()
            context.log.info(f"   - {col}: {unique_count} valores √∫nicos")
        
        return df_clean
        
    except Exception as e:
        context.log.error(f"‚ùå Error cr√≠tico en transformaci√≥n: {str(e)}")
        context.log.error(f"üìä Estado del DataFrame durante el error: {df_clean.shape if 'df_clean' in locals() else 'No definido'}")
        raise



#Asset para guardar el CSV limpio
@asset(group_name="ofertas")
def clean_csv_data_ofertas(context: AssetExecutionContext, clean_data_ofertas: pd.DataFrame):
    """Guardar CSV limpio - Depende de clean_data"""
    context.log.info("üíæ Guardando CSV limpio...")
    try:
        output_path = '/data/output/ofertas_limpio.csv'
        clean_data_ofertas.to_csv(output_path, index=False, encoding='utf-8')
        context.log.info(f"‚úÖ CSV guardado en: {output_path}")
        return output_path
    except Exception as e:
        context.log.error(f"‚ùå Error guardando CSV: {e}")
        raise


#asset para cargar a MongoDB
@asset(group_name="ofertas")
def mongodb_data_ofertas(context: AssetExecutionContext, clean_data_ofertas: pd.DataFrame):
    """Cargar a MongoDB - Depende de clean_data"""
    context.log.info("üçÉ Cargando a MongoDB...")
    
    try:
        # ‚úÖ Obtener URI desde variables de entorno
        mongo_uri = os.environ.get('MONGO_URI')
        
        if not mongo_uri:
            raise ValueError("‚ùå Variable de entorno MONGO_URI no configurada")
        
        context.log.info(f"üîó Conectando a MongoDB...")
        
        client = MongoClient(
            mongo_uri,
            authSource='admin',
            serverSelectionTimeoutMS=5000  # ‚úÖ Timeout para conexi√≥n
        )
        
        # ‚úÖ Verificar conexi√≥n
        client.admin.command('ping')
        context.log.info("‚úÖ Conexi√≥n a MongoDB verificada")
        
        db = client['etl_database']
        collection = db['ofertas_limpios']
        
        # ‚úÖ Contar documentos antes de borrar
        count_before = collection.count_documents({})
        if count_before > 0:
            context.log.info(f"üóëÔ∏è Eliminando {count_before} documentos existentes")
        
        collection.delete_many({})
        collection.insert_many(clean_data_ofertas.to_dict('records'))
        
        # ‚úÖ Verificar inserci√≥n
        count_after = collection.count_documents({})
        context.log.info(f"‚úÖ Insertados {count_after} documentos en MongoDB")
        
        return True
        
    except ValueError as e:
        context.log.error(str(e))
        raise
    except Exception as e:
        context.log.error(f"‚ùå Error cargando a MongoDB: {e}")
        raise
    finally:
        # ‚úÖ Cerrar conexi√≥n si existe
        if 'client' in locals():
            client.close()

    
#Asset para cargar a PostgreSQL
@asset(group_name="ofertas")
def postgres_data_ofertas(context: AssetExecutionContext, clean_data_ofertas: pd.DataFrame):
    """Cargar a PostgreSQL - Depende de clean_data"""
    context.log.info("üóÑÔ∏è Cargando a PostgreSQL...")
    
    try:
        # ‚úÖ Obtener URI desde variables de entorno
        postgres_uri = os.environ.get('POSTGRES_URI')
        
        if not postgres_uri:
            raise ValueError("‚ùå Variable de entorno POSTGRES_URI no configurada")
        
        context.log.info(f"üîó Conectando a: {postgres_uri.split('@')[-1]}")
        
        # ‚úÖ Usar la URI de las variables de entorno
        engine = create_engine(postgres_uri)
        
        # ‚úÖ Cargar datos
        clean_data_ofertas.to_sql('ofertas_limpios', engine, if_exists='replace', index=False)

        # ‚úÖ Verificar que se cargaron los datos
        with engine.connect() as conn:
            count = conn.execute("SELECT COUNT(*) FROM ofertas_limpios").scalar()
        
        context.log.info(f"‚úÖ Cargados {count} registros a PostgreSQL")
        return True
        
    except exc.SQLAlchemyError as e:
        context.log.error(f"‚ùå Error de base de datos: {e}")
        raise
    except ValueError as e:
        context.log.error(str(e))
        raise
    except Exception as e:
        context.log.error(f"‚ùå Error inesperado: {e}")
        raise


#asset para cargar a duckdb
@asset(group_name="ofertas")
def duckdb_data_ofertas(context: AssetExecutionContext, clean_data_ofertas: pd.DataFrame):
    """Cargar a DuckDB - Depende de clean_data"""
    context.log.info("ü¶Ü Cargando a DuckDB...")
    
    try:
        # Volver a la conexi√≥n local (no por red)
        con = duckdb.connect('/duckdb/data.db')  # ‚Üê ARCHIVO LOCAL
        context.log.info("‚úÖ Conectado a DuckDB local")

        con.register('temp_clean_data', clean_data_ofertas)
        con.execute("CREATE OR REPLACE TABLE ofertas_limpios AS SELECT * FROM temp_clean_data")

        count = con.execute("SELECT COUNT(*) FROM ofertas_limpios").fetchone()[0]
        context.log.info(f"üìä {count} registros insertados")
        
        con.close()
        return True
        
    except Exception as e:
        context.log.error(f"‚ùå Error cargando a DuckDB: {e}")
        raise