ğŸš€ ETL Pipeline with Dagster
ğŸ“Š DescripciÃ³n del Proyecto

Este proyecto es un pipeline ETL completo (Extract, Transform, Load) diseÃ±ado para procesar, limpiar y almacenar datos de manera eficiente y escalable. La soluciÃ³n automatiza el flujo de datos desde fuentes CSV hasta mÃºltiples bases de datos, garantizando calidad y consistencia en los datos.
ğŸ¯ Â¿Para quÃ© sirve?

    ğŸ“¥ ExtracciÃ³n: Carga datos desde archivos CSV

    ğŸ”„ TransformaciÃ³n: Limpieza, estandarizaciÃ³n y validaciÃ³n de datos

    ğŸ“¤ Carga: Almacenamiento en mÃºltiples bases de datos

    âš¡ OrquestaciÃ³n: CoordinaciÃ³n automÃ¡tica de todo el proceso ETL

ğŸ› ï¸ TecnologÃ­as Utilizadas
ğŸ—ï¸ Orchestration

    Dagster - OrquestaciÃ³n y scheduling de pipelines

    Docker - ContenerizaciÃ³n y despliegue

    Docker Compose - GestiÃ³n de multi-contenedores

ğŸ—„ï¸ Bases de Datos

    PostgreSQL - Almacenamiento estructurado de datos

    MongoDB - Almacenamiento documental flexible

    DuckDB - Base de datos analÃ­tica embebida

ğŸ Lenguaje & LibrerÃ­as

    Python 3.11 - Lenguaje principal

    Pandas - ManipulaciÃ³n y transformaciÃ³n de datos

    PyMongo - ConexiÃ³n con MongoDB

    SQLAlchemy - ConexiÃ³n con PostgreSQL

ğŸ“ Estructura del Proyecto
text

etl-dagster-project/
â”œâ”€â”€ dagster/                 # Orchestration core
â”‚   â”œâ”€â”€ infra/              # ConfiguraciÃ³n Docker
â”‚   â”œâ”€â”€ assets/             # DefiniciÃ³n de activos ETL
â”‚   â””â”€â”€ definitions.py      # DefiniciÃ³n del pipeline
â”œâ”€â”€ etl-worker/             # Worker de transformaciÃ³n
â”œâ”€â”€ data/                   # Volumen de datos (local)
â”‚   â”œâ”€â”€ input/              # Datos de entrada
â”‚   â”œâ”€â”€ output/             # Datos procesados
â”‚   â””â”€â”€ backup/             # Backups automÃ¡ticos
â”œâ”€â”€ duckdb/                 # Base DuckDB embebida
â””â”€â”€ docker-compose.yml      # OrquestaciÃ³n de servicios

ğŸ”„ Flujo del Pipeline
Diagram
Code
âœ¨ CaracterÃ­sticas Principales
ğŸ”„ Procesamiento de Datos

    ConversiÃ³n automÃ¡tica de tipos de datos

    Manejo de valores nulos y vacÃ­os

    EliminaciÃ³n de duplicados

    EstandarizaciÃ³n de formatos

ğŸ“Š Almacenamiento MÃºltiple

    PostgreSQL: Datos estructurados para aplicaciones

    MongoDB: Datos semi-estructurados para flexibilidad

    DuckDB: AnÃ¡lisis rÃ¡pido y consultas analÃ­ticas

âš™ï¸ ConfiguraciÃ³n

    Variables de entorno para configuraciÃ³n

    VolÃºmenes Docker para persistencia

    Health checks para monitorizaciÃ³n

    Logs detallados para debugging

ğŸš€ Como Ejecutar
bash

# Clonar repositorio
git clone https://github.com/Jhonnyxavier2729/etl-dagster-project.git

# Ejecutar con Docker Compose
docker-compose up -d

# Acceder a la interfaz Dagster
http://localhost:3000

ğŸ“ˆ Casos de Uso

    ğŸ“‹ MigraciÃ³n de datos entre sistemas

    ğŸ”„ SincronizaciÃ³n de bases de datos

    ğŸ“Š Reporting y analytics

    ğŸ§¹ Limpieza y estandarizaciÃ³n de datos

    âš¡ Procesamiento batch de archivos

ğŸ”§ ConfiguraciÃ³n

Las variables de entorno se configuran en docker-compose.yml:

    Credenciales de bases de datos

    Puertos de servicios

    Rutas de volÃºmenes

    ConfiguraciÃ³n de networking


â­ Si este proyecto te resulta Ãºtil, por favor dale una estrella en GitHub!
ğŸ–¼ï¸ Diagrama de Arquitectura

https://via.placeholder.com/800x400.png?text=ETL+Architecture+Diagram

Diagrama que muestra el flujo de datos entre los diferentes componentes del sistema ETL
ğŸ‘¥ ContribuciÃ³n

Las contribuciones son bienvenidas. Por favor:

    Fork el proyecto

    Crea una rama para tu feature

    Commit tus cambios

    Push a la rama

    Abre un Pull Request

ğŸ“ Soporte

Para preguntas o soporte:

    Abre un issue en GitHub

    Revisa la documentaciÃ³n de Dagster

    Consulta los logs de Docker
